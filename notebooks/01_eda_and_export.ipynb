{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a66de2-6de1-4c8d-9760-1fd42f69d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "RAW = Path(\"../data/raw/trans_3000p2_list.txt\")\n",
    "OUT = Path(\"../data/processed\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Quick read (first 200k rows) so we don't wait forever\n",
    "df_sample = pd.read_csv(RAW, nrows=200_000, low_memory=False)\n",
    "df_sample.columns = [c.strip().lower().replace(\" \", \"_\") for c in df_sample.columns]\n",
    "\n",
    "df_sample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9611d3cd-d525-4ef2-8c7c-dce165fd53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "RAW = Path(\"../data/raw/trans_3000p2_list.txt\")\n",
    "OUT = Path(\"../data/processed\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "chunksize = 300_000  # adjust up/down depending on your RAM\n",
    "\n",
    "banks = set()\n",
    "currencies = set()\n",
    "formats = set()\n",
    "\n",
    "# We'll compute daily KPIs from totals to avoid storing all data\n",
    "daily_accum = {}  # {date: {total_txns, total_amount_paid, flagged_txns}}\n",
    "\n",
    "for chunk in pd.read_csv(RAW, chunksize=chunksize, low_memory=False):\n",
    "    # normalize columns\n",
    "    chunk.columns = [c.strip().lower().replace(\" \", \"_\") for c in chunk.columns]\n",
    "\n",
    "    # handle duplicate account columns if present\n",
    "    if \"account\" in chunk.columns and \"account.1\" in chunk.columns:\n",
    "        chunk = chunk.rename(columns={\"account\": \"from_account\", \"account.1\": \"to_account\"})\n",
    "\n",
    "    # parse types we need\n",
    "    chunk[\"timestamp\"] = pd.to_datetime(chunk[\"timestamp\"], errors=\"coerce\")\n",
    "    chunk[\"amount_paid\"] = pd.to_numeric(chunk[\"amount_paid\"], errors=\"coerce\")\n",
    "    chunk[\"is_laundering\"] = pd.to_numeric(chunk[\"is_laundering\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "    # dimensions\n",
    "    banks.update(chunk[\"from_bank\"].astype(str).unique())\n",
    "    banks.update(chunk[\"to_bank\"].astype(str).unique())\n",
    "    currencies.update(chunk[\"receiving_currency\"].astype(str).unique())\n",
    "    currencies.update(chunk[\"payment_currency\"].astype(str).unique())\n",
    "    formats.update(chunk[\"payment_format\"].astype(str).unique())\n",
    "\n",
    "    # daily rollup\n",
    "    chunk[\"date\"] = chunk[\"timestamp\"].dt.date\n",
    "    g = chunk.groupby(\"date\", dropna=False).agg(\n",
    "        total_txns=(\"timestamp\", \"size\"),\n",
    "        total_amount_paid=(\"amount_paid\", \"sum\"),\n",
    "        flagged_txns=(\"is_laundering\", \"sum\"),\n",
    "    )\n",
    "\n",
    "    for date, row in g.iterrows():\n",
    "        if date not in daily_accum:\n",
    "            daily_accum[date] = {\"total_txns\": 0, \"total_amount_paid\": 0.0, \"flagged_txns\": 0}\n",
    "        daily_accum[date][\"total_txns\"] += int(row[\"total_txns\"])\n",
    "        daily_accum[date][\"total_amount_paid\"] += float(row[\"total_amount_paid\"]) if pd.notna(row[\"total_amount_paid\"]) else 0.0\n",
    "        daily_accum[date][\"flagged_txns\"] += int(row[\"flagged_txns\"])\n",
    "\n",
    "# build outputs\n",
    "daily = pd.DataFrame([\n",
    "    {\n",
    "        \"date\": d,\n",
    "        \"total_txns\": v[\"total_txns\"],\n",
    "        \"total_amount_paid\": v[\"total_amount_paid\"],\n",
    "        \"flagged_txns\": v[\"flagged_txns\"],\n",
    "        \"pct_flagged\": round((v[\"flagged_txns\"] / v[\"total_txns\"] * 100) if v[\"total_txns\"] else 0.0, 2),\n",
    "    }\n",
    "    for d, v in daily_accum.items()\n",
    "]).sort_values(\"date\")\n",
    "\n",
    "dim_bank = pd.DataFrame({\"bank\": sorted(banks)})\n",
    "dim_currency = pd.DataFrame({\"currency\": sorted(currencies)})\n",
    "dim_format = pd.DataFrame({\"payment_format\": sorted(formats)})\n",
    "\n",
    "# Save for Power BI\n",
    "daily.to_csv(OUT / \"daily_kpis.csv\", index=False)\n",
    "dim_bank.to_csv(OUT / \"dim_bank.csv\", index=False)\n",
    "dim_currency.to_csv(OUT / \"dim_currency.csv\", index=False)\n",
    "dim_format.to_csv(OUT / \"dim_payment_format.csv\", index=False)\n",
    "\n",
    "list(OUT.glob(\"*.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7fb512-a19f-411a-8c91-09bb09b91e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "OUT = Path(\"../data/processed\")\n",
    "\n",
    "for f in [\"daily_kpis.csv\", \"dim_bank.csv\", \"dim_currency.csv\", \"dim_payment_format.csv\"]:\n",
    "    p = OUT / f\n",
    "    print(f, \"exists:\", p.exists(), \"size:\", p.stat().st_size if p.exists() else None)\n",
    "\n",
    "pd.read_csv(OUT / \"daily_kpis.csv\").head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
